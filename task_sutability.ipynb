{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Imports and plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "from parlai.utils.strings import colorize\n",
    "import copy\n",
    "def compute_ngram_repeats(context: Union[str, List], model_text: Union[str, List], n=3, splitted=False):\n",
    "    cgrams = {}\n",
    "    # compute N grams of the context\n",
    "    \n",
    "    if not splitted:\n",
    "        context = context.split(' ')\n",
    "        model_text = model_text.split(' ')\n",
    "\n",
    "    for i in range(n, len(context) + 1):\n",
    "        ngram = ' '.join(context[i - n : i])\n",
    "        cgrams[ngram] = True\n",
    "    # compute N grams of the model response\n",
    "    creps = 0\n",
    "    lreps = 0\n",
    "    repetition_idxs = [0] * len(model_text)\n",
    "    lreps_idxs = [0] * len(model_text)\n",
    "    creps_idxs = [0] * len(model_text)\n",
    "    \n",
    "    lgrams = {}\n",
    "\n",
    "    for i in range(n, len(model_text) + 1):\n",
    "        ngram = ' '.join(model_text[i - n : i])\n",
    "        \n",
    "        if ngram in cgrams:\n",
    "            creps = creps + 1\n",
    "            repetition_idxs[i-1] = 1\n",
    "            creps_idxs[i-1] = 1\n",
    "        \n",
    "        if ngram in lgrams:\n",
    "            lreps = lreps + 1\n",
    "            repetition_idxs[i-1] = 1\n",
    "            lreps_idxs[i-1] = 1\n",
    "           \n",
    "        lgrams[ngram] = True\n",
    "    \n",
    "    for i in range(n-1, len(model_text)):\n",
    "        if repetition_idxs[i] == 1:\n",
    "            for j in range(1, n):\n",
    "                repetition_idxs[i-j] = 1\n",
    "\n",
    "        if creps_idxs[i] == 1:\n",
    "            for j in range(1, n):\n",
    "                creps_idxs[i-j] = 1\n",
    "\n",
    "        if lreps_idxs[i] == 1:\n",
    "            for j in range(1, n):\n",
    "                lreps_idxs[i-j] = 1\n",
    "\n",
    "    return creps + lreps, creps, lreps, repetition_idxs, creps_idxs, lreps_idxs\n",
    "\n",
    "\n",
    "def print_with_colors(text, repeat_indices):\n",
    "    colorized_tokens = []\n",
    "    tokenized_text = text.split(\" \")\n",
    "    \n",
    "    is_repeat_indices = copy.copy(repeat_indices)\n",
    "    for (token, is_repeat) in zip(tokenized_text, is_repeat_indices):\n",
    "       \n",
    "        if is_repeat:\n",
    "            colorized_token = colorize(token, \"red\")\n",
    "        else:\n",
    "            colorized_token = token\n",
    "\n",
    "        colorized_tokens.append(colorized_token)\n",
    "\n",
    "    return \" \".join(colorized_tokens)\n",
    "\n",
    "def print_sample(context, model_text, repeat_type='all'):\n",
    "    _, _, _, arep_idxs, crep_idxs, lrep_idxs = compute_ngram_repeats(context, model_text)\n",
    "    # print(context)\n",
    "\n",
    "    rep_idxs = None\n",
    "    if repeat_type == 'all':\n",
    "        rep_idxs = arep_idxs\n",
    "    elif repeat_type == 'context':\n",
    "        rep_idxs = crep_idxs\n",
    "    elif repeat_type == 'labels':\n",
    "        rep_idxs = lrep_idxs\n",
    "\n",
    "    print(print_with_colors(model_text, rep_idxs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narrative QA Dataset\n",
    "\n",
    "This dataset is not suitable for our use case as the answers are very small. \n",
    "Maybe this can be used in another setting where we generate summary from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6537ba95cd421fb57735639b4cf080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14a2ba7b55042d896116fcb4b70b372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset narrativeqa/default (download: 183.61 MiB, generated: 15.21 GiB, post-processed: Unknown size, total: 15.38 GiB) to /home/mila/a/arorakus/scratch/.cache/huggingface/datasets/narrativeqa/default/0.0.0/daef7ccc51ec258bef464658d11751bb20f033da9b4c219fd84563b3a4af0422...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6345170b94304103a34e300f19a2c991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2def5795668146e6b2a07cf1333c57a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdec9ba62294f208870560757fa0783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/32747 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1384c0fb4d94c9392980416771d3e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10557 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2288c787a6094cbe9af90634bf13eca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3461 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset narrativeqa downloaded and prepared to /home/mila/a/arorakus/scratch/.cache/huggingface/datasets/narrativeqa/default/0.0.0/daef7ccc51ec258bef464658d11751bb20f033da9b4c219fd84563b3a4af0422. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f263bcc6954134bc409bcc895d4201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"narrativeqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['document', 'question', 'answers'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][1000]\n",
    "example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document:  Following his pursuit by Kirill (in The Bourne Supremacy), Jason Bourne (Matt Damon) evades Moscow police while wounded, and deals with more flashbacks of when he first joined Operation Treadstone. Six weeks later, CIA Deputy Director Pamela Landy (Joan Allen) divulges the audiotaped confession of Ward Abbott, the late former head of Treadstone, to Director Ezra Kramer (Scott Glenn). Meanwhile, in Turin, journalist Simon Ross (Paddy Considine) of The Guardian meets an informant to learn about Bourne and Operation Blackbriar, the program succeeding Treadstone. The CIA tracks Ross as he returns to London, after his mention of \"Blackbriar\" during a cell-phone call to his editor is detected by the ECHELON system. Bourne reappears in Paris to inform Martin Kreutz (Daniel Brühl), the step-brother of his girlfriend Marie Helena Kreutz (Franka Potente), of her assassination in India, also in the previous film.\n",
      "Bourne reads Ross's articles and arranges a meeting with him at London Waterloo sta\n",
      "Question: What is the name of the operation Bourne joins?\n",
      "Answers:\n",
      "\t1. Treadstone\n",
      "\t2. treadstone\n"
     ]
    }
   ],
   "source": [
    "print(\"Document: \" + example['document']['summary']['text'][:1000])\n",
    "print(\"Question: \" + example['question']['text'])\n",
    "print(f\"Answers:\")\n",
    "for i, answer in enumerate(example['answers']):\n",
    "    print(f\"\\t{i+1}. {answer['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "The answer size here is pretty small, hence this is not very suitable for our use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration rewardsignal--reddit_writing_prompts-dd5d2a64487ab606\n",
      "Reusing dataset csv (/home/mila/a/arorakus/scratch/.cache/huggingface/datasets/csv/rewardsignal--reddit_writing_prompts-dd5d2a64487ab606/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb18639b22564d7d9682766c042f2a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "prompt_response_dataset = load_dataset(\"rewardsignal/reddit_writing_prompts\", data_files=\"prompt_responses_full.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[WP] \"Ma'am you can't bring your emotional support dragon inside the restaurant.\"\n",
      "\n",
      "Response:\n",
      "The manager saw the lady in the vest coming a mile away. Literally. It wasn't a small dragon. It lumbered up the path to the Hilltop Restaurant.\n",
      "\n",
      "*\\*sigh\\* Not again*, thought the manager. Last time this happened... Have you ever tried pushing a fire-breathing dragon out of a restaurant? It's not easy.\n",
      "\n",
      "He signaled to the waiter to keep inside and be ready on backup. At least this dragon seemed more... behaved? It was looking around and trying to be careful. But, rules were rules.\n",
      "\n",
      "He walked outside, put up his hand, and said, \"Ma'am you can't bring your emotional support dragon inside the restaurant.\"\n",
      "\n",
      "The dragon yipped and grabbed the woman, holding her tight. \"Ssh, ssh. It's OK. He's not trying to hurt you,\" she cooed while stroking it softly. \"Hug me as long as you need to.\" The dragon stopped shaking, but just stared wide-eyed at the manager.\n",
      "\n",
      "She turned her head, looked at the manager, and pointed to the symbol on her vest. \"I'm afraid there's been a misunderstanding. I'm his emotional support human.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt:\")\n",
    "print(prompt_response_dataset['train'][0]['prompt'])\n",
    "print()\n",
    "print(\"Response:\")\n",
    "print(prompt_response_dataset['train'][0]['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "gpt2_finetuned_model = AutoModelForCausalLM.from_pretrained(\"/home/mila/a/arorakus/scratch/ews/finetuned_writing_prompts/08-13-2022-05-56/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELI-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yjernite/bart_eli5\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"yjernite/bart_eli5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ef885cb66943bb8006438f97c47c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2a18b6eee64d128258c38b711b5a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset eli5/LFQA_reddit (download: 6.03 MiB, generated: 1.26 GiB, post-processed: Unknown size, total: 1.26 GiB) to /home/mila/a/arorakus/scratch/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/17574e5502a10f41bbd17beba83e22475b499fa62caa1384a3d093fc856fe6fa...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c604f5a880054fd79dc41a7b6ec170a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c0a14eb9a64c3989341936200a02ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/576M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633bab5fd6b149519f2bf4abf1f8adc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/21.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f7b83b4c084bb7b84bd4c8838a7a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe7be0dae8248b48d943c600bd1e115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/286M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dc65999dea4b3ea2730a5f86470f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca7ecf5600f4b4aad23281288b5a158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634f7b041519454fad081997b2c09738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/330M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c852e6788240cba5746b6cb1fae99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aa55f7248743baacd0c656e5b1c72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/36.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset eli5 downloaded and prepared to /home/mila/a/arorakus/scratch/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/17574e5502a10f41bbd17beba83e22475b499fa62caa1384a3d093fc856fe6fa. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd94755d6c38423f969dc37094bc1744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"eli5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '359ec0',\n",
       " 'title': 'Why do planes seem to ”rock\" side-to-side when taking off?',\n",
       " 'selftext': \"I've recently been employed in a position that requires me to travel a lot. I've noticed that when taking off from a runway, planes seem to rock side to side on the runway before they take off. Any explanation would help my peace of mind.\",\n",
       " 'document': '',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['cr29zuw'],\n",
       "  'text': ['Not quite sure when you\\'re experiencing the rocking, I\\'m assuming it\\'s just before you reach speed where the wheels lift off the ground?\\n\\nIf so, a key thing to realize is that large passenger planes are actually VERY flexible. They\\'re designed that way to allow shock absorption and deal with some pretty large stresses when you\\'re flying through turbulent or wind-gusty air that might hit one part of the plane differently from another or shove it around a little. A brittle plane that experiences those stresses might snap, but a flexible plane \"bends with the wind\".\\n\\nAs part of that flexibility and design, there\\'s a tremendous amount of metal (even if it\\'s aluminum) in the wings and they push far out from the body of the plane that adds a bounciness when it\\'s going fairly fast along the ground. As you shoot down the runway (and particularly bumpy runways), those wings bend a bit and can add a small rocking or side-to-side motion to the plane\\'s apparent trajectory as they jounce around while coming up to speed.'],\n",
       "  'score': [2]},\n",
       " 'title_urls': {'url': []},\n",
       " 'selftext_urls': {'url': []},\n",
       " 'answers_urls': {'url': []}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test_eli5'][1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "question = dataset['test_eli5'][1234]['selftext']\n",
    "tok = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "\n",
    "batch = tok(question, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' When taking off from a runway, planes seem to rock side to side on the runway before']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids = model.generate(batch[\"input_ids\"],  do_sample=True, top_p=0.9, min_length=100)\n",
    "\n",
    "tok.batch_decode(generated_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArXiv Summarization   \n",
    "\n",
    "The summaries generated here are pretty good by the looks of it but these are very extractive and copies heavily from the source text. \n",
    "Can this be a symptom of degradation, where context is being copied in huge chunks rather than being abstractive in nature?\n",
    "Can something like entropy aware beam (or greedy) search  reduce the extractiveness of the summary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset scientific_papers (/home/mila/a/arorakus/scratch/.cache/huggingface/datasets/scientific_papers/arxiv/1.1.1/306757013fb6f37089b6a75469e6638a553bd9f009484938d8f75a4c5e84206f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d579a0b93c25496fb8f63f92d8d4a862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# pubmed_summ_dataset = load_dataset(\"scientific_papers\", \"pubmed\")\n",
    "arxiv_summ_dataset = load_dataset(\"scientific_papers\", \"arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'abstract', 'section_names'],\n",
       "    num_rows: 6440\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_summ_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "bigbird_arxiv_tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
    "\n",
    "bigbird_arxiv_model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " we study the detectability of circular polarization in a stochastic gravitational wave background from various sources such as supermassive black hole binaries , cosmic strings , and inflation in the early universe with pulsar timing arrays . \n",
      " we calculate generalized overlap reduction functions for the circularly polarized stochastic gravitational wave background . \n",
      " we find that the circular polarization can not be detected for an isotropic background . however , there is a chance to observe the circular polarization for an anisotropic gravitational wave background . \n",
      " we also show how to separate polarized gravitational waves from unpolarized gravitational waves . \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "arxiv_summ_testset = arxiv_summ_dataset['test']\n",
    "\n",
    "idx = random.randint(0, len(arxiv_summ_testset))\n",
    "\n",
    "text = arxiv_summ_dataset['test'][idx]['article']\n",
    "abstract = arxiv_summ_dataset['test'][idx]['abstract']\n",
    "\n",
    "text = ' '.join(text.split()[:2000])\n",
    "\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> we investigate the detectability of circular polarization in the stochastic gravitational wave background ( sgwb ) by pulsar timing arrays ( ptas ). we characterize the sgwb by the so called stokes @xmath0 parameter and calculate generalized overlap reduction functions ( orfs ) so that we can probe the circular polarization of the sgwb.<n> we also discuss a method to separate the intensity ( @xmath1 mode ) and circular polarization ( @xmath2 mode ) of the sgwb.</s>']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = bigbird_arxiv_tokenizer(text, return_tensors='pt')\n",
    "prediction = bigbird_arxiv_model.generate(**inputs)\n",
    "prediction = bigbird_arxiv_tokenizer.batch_decode(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is believed that the direct detection of gravitational waves ( gws ) will bring the era of gravitational wave astronomy . the interferometer detectors are now under operation and awaiting the first signal of gws @xcite . it is also known that \u001b[0;31mpulsar\u001b[0;0m \u001b[0;31mtiming\u001b[0;0m \u001b[0;31marrays\u001b[0;0m \u001b[0;31m(\u001b[0;0m \u001b[0;31mptas\u001b[0;0m ) can be used as a detector for gws @xcite . these detectors are used to search for very low frequency ( @xmath0 ) gravitational waves , where the lower limit of the observable frequencies is determined by the inverse of total observation time @xmath1 . indeed , the total observation time has a crucial role in ptas , because ptas are most sensitive near the lower edge of observable frequencies @xcite . taking into account its sensitivity , the first direct detection of the gravitational waves might be achieved by ptas . the main target of ptas is \u001b[0;31mthe\u001b[0;0m \u001b[0;31mstochastic\u001b[0;0m \u001b[0;31mgravitational\u001b[0;0m \u001b[0;31mwave\u001b[0;0m \u001b[0;31mbackground\u001b[0;0m \u001b[0;31m(\u001b[0;0m \u001b[0;31msgwb\u001b[0;0m \u001b[0;31m)\u001b[0;0m generated by a large number of unresolved sources with the astrophysical origin or the cosmological origin in the early universe . the promising sources are super massive black hole binaries @xcite , cosmic ( super)string @xcite , and inflation @xcite . previous studies have assumed that the sgwb is isotropic and unpolarized @xcite . these assumptions are reasonable for the primary detection of the sgwb , but the deviation from the isotropy and the polarizations should have rich information of sources of gravitational waves . recently , the cross - correlation formalism has been generalized to deal with anisotropy in the sgwb @xcite . result of this work enables us to consider arbitrary levels of anisotropy , and a bayesian approach was performed by using this formalism @xcite . on the other hand , for the anisotropy of the sgwb , the cross - correlation formalism has been also developed in the case of interferometer detectors @xcite . as to the polarization , there are works including the ones motivated by the modified gravity @xcite . we can envisage supermassive black hole binaries emit circularly polarized sgwb due to the chern - simons term @xcite . there may also exist cosmological sgwb with \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m \u001b[0;31min\u001b[0;0m \u001b[0;31mthe\u001b[0;0m presence of parity violating term in gravity sector @xcite . in this paper , \u001b[0;31mwe\u001b[0;0m \u001b[0;31minvestigate\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mdetectability\u001b[0;0m \u001b[0;31mof\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m \u001b[0;31min\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31msgwb\u001b[0;0m \u001b[0;31mby\u001b[0;0m ptas . we characterize \u001b[0;31msgwb\u001b[0;0m \u001b[0;31mby\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mso\u001b[0;0m \u001b[0;31mcalled\u001b[0;0m \u001b[0;31mstokes\u001b[0;0m @xmath2 parameter @xcite \u001b[0;31mand\u001b[0;0m \u001b[0;31mcalculate\u001b[0;0m \u001b[0;31mgeneralized\u001b[0;0m \u001b[0;31moverlap\u001b[0;0m \u001b[0;31mreduction\u001b[0;0m \u001b[0;31mfunctions\u001b[0;0m \u001b[0;31m(\u001b[0;0m \u001b[0;31morfs\u001b[0;0m \u001b[0;31m)\u001b[0;0m \u001b[0;31mso\u001b[0;0m \u001b[0;31mthat\u001b[0;0m \u001b[0;31mwe\u001b[0;0m \u001b[0;31mcan\u001b[0;0m \u001b[0;31mprobe\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m \u001b[0;31mof\u001b[0;0m \u001b[0;31mthe\u001b[0;0m sgwb . \u001b[0;31mwe\u001b[0;0m \u001b[0;31malso\u001b[0;0m \u001b[0;31mdiscuss\u001b[0;0m \u001b[0;31ma\u001b[0;0m \u001b[0;31mmethod\u001b[0;0m \u001b[0;31mto\u001b[0;0m \u001b[0;31mseparate\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mintensity\u001b[0;0m \u001b[0;31m(\u001b[0;0m @xmath3 \u001b[0;31mmode\u001b[0;0m \u001b[0;31m)\u001b[0;0m \u001b[0;31mand\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m \u001b[0;31m(\u001b[0;0m \u001b[0;31m@xmath2\u001b[0;0m \u001b[0;31mmode\u001b[0;0m \u001b[0;31m)\u001b[0;0m \u001b[0;31mof\u001b[0;0m \u001b[0;31mthe\u001b[0;0m sgwb . the paper is organized as follows . in section [ sec : stokes parameters for a plane gravitational wave ] , we introduce the stokes parameters for monochromatic plane gravitational waves , and clarify the physical meaning of the stokes parameters @xmath3 and @xmath2 . in section [ sec : formulation ] , we formulate the cross - correlation formalism for anisotropic circularly polarized sgwb with ptas . the basic framework is essentially a combination of the formalism of @xcite , and the polarization decomposition formula of the sgwb derived in @xcite . in section [ sec : the \u001b[0;31mgeneralized\u001b[0;0m \u001b[0;31moverlap\u001b[0;0m \u001b[0;31mreduction\u001b[0;0m function for circular polarization ] , we calculate the generalized orfs for the @xmath2 mode . the results for @xmath3 mode are consistent with the previous work @xcite . in section [ sec : separation method ] , we give a method for separation between the @xmath3 mode and @xmath2 mode of the sgwb . the final section is devoted to the conclusion . in appendixes , we present analytic results for the \u001b[0;31mgeneralized\u001b[0;0m \u001b[0;31moverlap\u001b[0;0m \u001b[0;31mreduction\u001b[0;0m \u001b[0;31mfunctions\u001b[0;0m . in this paper , we will use the gravitational units @xmath4 . let us consider the stokes parameters for plane waves traveling in the direction @xmath5 , which can be described by @xmath6 \\ , \\\\ & & h_{xy}(t , z)=h_{yx}(t , z)={\\rm re}[b_{\\times}\\mathrm{e}^{-iw(t - z ) } ] \\ .\\end{aligned}\\ ] ] for an idealized monochromatic plane wave , complex amplitudes @xmath7 and @xmath8 are constants . \u001b[0;31mpolarization\u001b[0;0m \u001b[0;31mof\u001b[0;0m \u001b[0;31mthe\u001b[0;0m plane gws is characterized by the tensor , ( see @xcite and also electromagnetic case @xcite ) @xmath9 where @xmath10 take @xmath11 . any @xmath12 hermitian matrix can be expanded by the pauli and the unit matrices with real coefficients . hence , the @xmath13 hermitian matrix @xmath14 can be written as @xmath15 where @xmath16 by analogy with electromagnetic cases , @xmath17 and @xmath2 are called stokes parameters . comparing with , we can read off the stokes parameters as @xmath18= b_{+}^{\\ast}b_{\\times}+ b_{\\times}^{\\ast}b_{+},\\\\ v&=&-2{\\rm i m } [ b_{+}^{\\ast}b_{\\times}]=i ( b_{+}^{\\ast}b_{\\times}- b_{\\times}^{\\ast}b_{+}).\\label{stv}\\end{aligned}\\ ] ] apparently , the real parameter @xmath3 is the intensity of gws . in order to reveal the physical meaning of the real parameter @xmath2 , we define \u001b[0;31mthe\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m bases @xcite @xmath19 from the relation @xmath20 we see @xmath21 thus , we can rewrite the stokes parameters - as @xmath22 from the above expression , we see that the real parameter @xmath2 characterizes the asymmetry \u001b[0;31mof\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m amplitudes . the other parameters @xmath23 and @xmath24 have additional information about linear polarizations by analogy with the electromagnetic cases . alternatively , we can also define the tensor @xmath25 in circular polarization bases @xmath26 where @xmath27 . note that the stokes parameters satisfy a relation @xmath28 next , we consider the transformation of the stokes parameters under rotations around the @xmath5 axis . the rotation around the @xmath5 axis is given by @xmath29 where @xmath30 is the angle of the rotation . the gws traveling in the direction @xmath5 @xmath31 transform as @xmath32 where we took the transverse traceless gauge @xmath33 after a short calculation , we obtain @xmath34 using and , the four stokes parameters ( [ sti])-([stv ] ) transform as @xmath35 as you can see , the parameters @xmath23 and @xmath24 depend on the rotation angle @xmath30 . this reflects the fact that @xmath23 and @xmath24 parameters characterize linear polarizations . note that this transformation is similar to the transformation of electromagnetic case except for the angle @xmath36 and can be rewritten as @xmath37 in this section , we study anisotropic distribution of sgwb and focus on \u001b[0;31mthe\u001b[0;0m \u001b[0;31mdetectability\u001b[0;0m \u001b[0;31mof\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m polarizations with \u001b[0;31mpulsar\u001b[0;0m \u001b[0;31mtiming\u001b[0;0m \u001b[0;31marrays\u001b[0;0m . we combine the analysis of @xcite and that of @xcite . in sec.[subsec : the spectral ] , we derive the power spectral density for anisotropic circularly polarized sgwb @xmath38 . then we also derive the dimensionless density parameter @xmath39 which is expressed by the frequency spectrum of intensity @xmath40 @xcite . in sec.[subsec : the signal ] , we extend the generalized orfs to cases with circular polarizations characterized by the parameter @xmath2 . for simplicity , we consider specific anisotropic patterns with @xmath41 expressed by the spherical harmonics @xmath42 . in the transverse traceless gauge , metric perturbations @xmath43 with a given propagation direction @xmath44 can be expanded as @xcite @xmath45 where the fourier amplitude satisfies @xmath46 as a consequence of the reality of @xmath43 , @xmath47 , @xmath48 is the frequency of the gws , @xmath49 are spatial indices , @xmath50 label polarizations . note that the fourier amplitude @xmath51 satisfies the relation @xmath52 where @xmath53 was defined by . the polarized tensors @xmath54 are defined by @xmath55 where @xmath56 and @xmath57 are unit orthogonal vectors perpendicular to @xmath58 . the polarization tensors satisfy @xmath59 with polar coordinates , the direction @xmath44 can be represented by @xmath60 and the polarization basis vectors read @xmath61 we assume the fourier amplitudes @xmath62 are random variables , which is stationary and gaussian . however , they are not isotropic and unpolarized . the ensemble average of fourier amplitudes can be written as @xcite @xmath63 where @xmath64 here , the bracket @xmath65 represents an ensemble average , and @xmath66 is the dirac delta function on the two - sphere . the gw power spectral density @xmath38 is a hermitian matrix , and satisfies @xmath67 because of the relation @xmath46 . therefore , we have the relations @xmath68 note that the stokes parameters are not exactly the same as the expression of , but they have the relation and characterize the same polarization . we further assume that the sgwbs satisfy @xmath69 we also assume the directional dependence of the sgwb is frequency independent @xcite . this implies the gw power spectral density is factorized into two parts , one of which depends on the direction while the other depends on the frequency . because of the transformations - , the parameters @xmath3 and @xmath2 have spin 0 and the parameters @xmath70 have spin @xmath71 @xcite . to analyze the sgwb on the sky , it is convenient to expand the stokes parameters by spherical harmonics @xmath72 . however , since @xmath70 parameters have spin @xmath71 , they have to be expanded by the spin - weighted harmonics @xmath73 @xcite . thus , we obtain @xmath74 in this paper , we study specific anisotropic patterns with @xmath41 for simplicity . therefore , we can neglect @xmath23 and @xmath24 from now on . thus , the gw power spectral density becomes @xmath75 where @xmath76 so , we focus on the parameters @xmath3 and @xmath2 . in what follows , we will use the following shorthand notation @xmath77 next , we consider the dimensionless density parameter @xcite @xmath78 where @xmath79 is the critical density , @xmath80 is the present value of the hubble parameter , @xmath81 is the energy density of gravitational waves , and @xmath82 is the energy density in the frequency range @xmath48 to @xmath83 . the bracket @xmath65 represents the ensemble average . however , actually , we take a spatial average over the wave lengths @xmath84 of gws or a temporal average over the periods @xmath85 of gws . here , we assumed the ergodicity , namely , the ensemble average can be replaced by the temporal average . using , , , as well as @xmath46 and @xmath86 , we get @xmath87 then we define @xmath88 hence , the dimensionless quantity @xmath39 in is given by @xmath89 where the spherical harmonics are orthogonal and normalized as @xmath90 using @xmath91 , we obtain @xmath92 without loss of generality , we normalize the monopole moment as @xmath93 so , becomes @xmath94 the time of arrival of radio pulses from the pulsar is affected by gws . consider a pulsar with frequency @xmath95 located in the direction @xmath96 . to detect the sgwb , let us consider the redshift of the pulse from a pulsar @xcite @xmath97 where @xmath98 is a frequency detected at the earth and @xmath96 is the direction to the pulsar . the unit vector @xmath44 represents the direction of propagation of gravitational plane waves . we also defined the difference between the metric perturbations at the pulsar @xmath99 and at the earth @xmath100 as @xmath101 the gravitational plane waves at each point is defined as @xmath102 for the sgwb , the redshift have to be integrated over the direction of propagation of the gravitational waves @xmath44 : @xmath103 we choose a coordinate system @xmath104 and assume that the amplitudes of the metric perturbation at the pulsar and the earth are the same . then becomes @xmath105 and therefore , reads @xmath106 where we have defined the pattern functions for pulsars @xmath107 note that our convention for the fourier transformation is @xmath108 therefore , the fourier transformation of can be written as @xmath109 in the actual signals from a pulsar , there exist noises . hence , we need to use the correlation analysis . we consider the signals from two pulsars @xmath110 where @xmath111 labels the pulsar . here , @xmath112 denotes the signal from the pulsar and @xmath113 denotes the noise intrinsic to the measurement . we assume the noises are stationary , gaussian and are not correlated between the two pulsars . to correlate the signals\n",
      "Abstract:\n",
      " we study \u001b[0;31mthe\u001b[0;0m \u001b[0;31mdetectability\u001b[0;0m \u001b[0;31mof\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m \u001b[0;31min\u001b[0;0m a \u001b[0;31mstochastic\u001b[0;0m \u001b[0;31mgravitational\u001b[0;0m \u001b[0;31mwave\u001b[0;0m \u001b[0;31mbackground\u001b[0;0m from various sources such as \u001b[0;31msupermassive\u001b[0;0m \u001b[0;31mblack\u001b[0;0m \u001b[0;31mhole\u001b[0;0m \u001b[0;31mbinaries\u001b[0;0m , cosmic strings \u001b[0;31m,\u001b[0;0m \u001b[0;31mand\u001b[0;0m \u001b[0;31minflation\u001b[0;0m \u001b[0;31min\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mearly\u001b[0;0m \u001b[0;31muniverse\u001b[0;0m \u001b[0;31mwith\u001b[0;0m \u001b[0;31mpulsar\u001b[0;0m \u001b[0;31mtiming\u001b[0;0m \u001b[0;31marrays\u001b[0;0m \u001b[0;31m.\u001b[0;0m \n",
      " we \u001b[0;31mcalculate\u001b[0;0m \u001b[0;31mgeneralized\u001b[0;0m \u001b[0;31moverlap\u001b[0;0m \u001b[0;31mreduction\u001b[0;0m \u001b[0;31mfunctions\u001b[0;0m for the circularly polarized \u001b[0;31mstochastic\u001b[0;0m \u001b[0;31mgravitational\u001b[0;0m \u001b[0;31mwave\u001b[0;0m \u001b[0;31mbackground\u001b[0;0m \u001b[0;31m.\u001b[0;0m \u001b[0;31m\n",
      "\u001b[0;0m \u001b[0;31mwe\u001b[0;0m find that \u001b[0;31mthe\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m can not be detected for an isotropic background \u001b[0;31m.\u001b[0;0m \u001b[0;31mhowever\u001b[0;0m \u001b[0;31m,\u001b[0;0m there is a chance to observe \u001b[0;31mthe\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m for an anisotropic \u001b[0;31mgravitational\u001b[0;0m \u001b[0;31mwave\u001b[0;0m \u001b[0;31mbackground\u001b[0;0m \u001b[0;31m.\u001b[0;0m \u001b[0;31m\n",
      "\u001b[0;0m \u001b[0;31mwe\u001b[0;0m also show how to separate polarized gravitational waves from unpolarized \u001b[0;31mgravitational\u001b[0;0m \u001b[0;31mwaves\u001b[0;0m \u001b[0;31m.\u001b[0;0m \n",
      "Summary:\n",
      "\n",
      "Context Repeats Highlighted\n",
      "<s> \u001b[0;31mwe\u001b[0;0m \u001b[0;31minvestigate\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mdetectability\u001b[0;0m \u001b[0;31mof\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m \u001b[0;31min\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mstochastic\u001b[0;0m \u001b[0;31mgravitational\u001b[0;0m \u001b[0;31mwave\u001b[0;0m \u001b[0;31mbackground\u001b[0;0m \u001b[0;31m(\u001b[0;0m \u001b[0;31msgwb\u001b[0;0m \u001b[0;31m)\u001b[0;0m by \u001b[0;31mpulsar\u001b[0;0m \u001b[0;31mtiming\u001b[0;0m \u001b[0;31marrays\u001b[0;0m \u001b[0;31m(\u001b[0;0m \u001b[0;31mptas\u001b[0;0m ). we characterize \u001b[0;31mthe\u001b[0;0m \u001b[0;31msgwb\u001b[0;0m \u001b[0;31mby\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mso\u001b[0;0m \u001b[0;31mcalled\u001b[0;0m \u001b[0;31mstokes\u001b[0;0m @xmath0 parameter \u001b[0;31mand\u001b[0;0m \u001b[0;31mcalculate\u001b[0;0m \u001b[0;31mgeneralized\u001b[0;0m \u001b[0;31moverlap\u001b[0;0m \u001b[0;31mreduction\u001b[0;0m \u001b[0;31mfunctions\u001b[0;0m \u001b[0;31m(\u001b[0;0m \u001b[0;31morfs\u001b[0;0m \u001b[0;31m)\u001b[0;0m \u001b[0;31mso\u001b[0;0m \u001b[0;31mthat\u001b[0;0m \u001b[0;31mwe\u001b[0;0m \u001b[0;31mcan\u001b[0;0m \u001b[0;31mprobe\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m \u001b[0;31mof\u001b[0;0m \u001b[0;31mthe\u001b[0;0m sgwb.<n> \u001b[0;31mwe\u001b[0;0m \u001b[0;31malso\u001b[0;0m \u001b[0;31mdiscuss\u001b[0;0m \u001b[0;31ma\u001b[0;0m \u001b[0;31mmethod\u001b[0;0m \u001b[0;31mto\u001b[0;0m \u001b[0;31mseparate\u001b[0;0m \u001b[0;31mthe\u001b[0;0m \u001b[0;31mintensity\u001b[0;0m \u001b[0;31m(\u001b[0;0m @xmath1 \u001b[0;31mmode\u001b[0;0m \u001b[0;31m)\u001b[0;0m \u001b[0;31mand\u001b[0;0m \u001b[0;31mcircular\u001b[0;0m \u001b[0;31mpolarization\u001b[0;0m \u001b[0;31m(\u001b[0;0m \u001b[0;31m@xmath2\u001b[0;0m \u001b[0;31mmode\u001b[0;0m \u001b[0;31m)\u001b[0;0m \u001b[0;31mof\u001b[0;0m \u001b[0;31mthe\u001b[0;0m sgwb.</s>\n",
      "\n",
      "Label Repeats Highlighted\n",
      "<s> we investigate the detectability of circular polarization in the stochastic gravitational wave background ( sgwb ) by pulsar timing arrays ( ptas ). we characterize the sgwb by the so called stokes @xmath0 parameter and calculate generalized overlap reduction functions ( orfs ) so that we can probe the circular polarization of the sgwb.<n> we also discuss a method to separate the intensity ( @xmath1 mode ) and circular polarization ( @xmath2 mode ) of the sgwb.</s>\n"
     ]
    }
   ],
   "source": [
    "print_sample(prediction[0], text, repeat_type='context')\n",
    "\n",
    "print(\"Abstract:\")\n",
    "print_sample(text, abstract)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print()\n",
    "print(\"Context Repeats Highlighted\")\n",
    "print_sample(text, prediction[0], repeat_type='all')\n",
    "print()\n",
    "\n",
    "print(\"Label Repeats Highlighted\")\n",
    "print_sample(text, prediction[0], repeat_type='labels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xsum & Pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/mila/a/arorakus/scratch/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b5541450574522bf433809e6122e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "xsum_dataset = load_dataset(\"xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "pegasus_tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "pegasus_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document:\n",
      "A red Ford Fiesta travelling north at Drumjohn, near Carsphairn, was in collision with a white Asda delivery van heading south at about 10:40 on Friday.\n",
      "The van driver Scott Kennedy, 46, was taken by ambulance to Ayr Hospital where he died a short time later.\n",
      "The Fiesta driver,  50 year old Antony Sztuka, died at the scene.\n",
      "Both men were from Ayrshire.\n",
      "The A713 was re-opened around 18:45 hours.\n",
      "Sgt Billy McEwan, of Police Scotland, said: \"We would like to hear from anyone who was in the area of the time of the crash to contact police.\n",
      "\"We know from witnesses already spoken to that there was a white flat-bed pickup truck - the size of a transit van - on the road at the time of the crash.\n",
      "\"We are very keen to speak to the driver as he or she may have information that could prove vital to the investigation.\"\n",
      "\n",
      "Summary:\n",
      "Two men have died following a road crash on the A713 in Dumfries and Galloway.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "xsum_testset = xsum_dataset['test']\n",
    "\n",
    "idx = random.randint(0, len(xsum_testset))\n",
    "\n",
    "xsum_document = xsum_testset[idx]['document']\n",
    "xsum_summary = xsum_testset[idx]['summary']\n",
    "\n",
    "print(\"Document:\")\n",
    "print(xsum_document)\n",
    "print()\n",
    "print(\"Summary:\")\n",
    "print(xsum_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<pad> Two men have died in a crash on the A713 in South Ayrshire.</s>']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = pegasus_tokenizer(xsum_document, max_length=512, truncation=True, return_tensors='pt')\n",
    "\n",
    "prediction = pegasus_model.generate(**inputs)\n",
    "prediction = pegasus_tokenizer.batch_decode(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A red Ford Fiesta travelling north at Drumjohn, near Carsphairn, was in collision with a white Asda delivery van heading south at about 10:40 on Friday.\n",
      "The van driver Scott Kennedy, 46, was taken by ambulance to Ayr Hospital where he died a short time later.\n",
      "The Fiesta driver,  50 year old Antony Sztuka, died at the scene.\n",
      "Both men were from Ayrshire.\n",
      "The A713 was re-opened around 18:45 hours.\n",
      "Sgt Billy McEwan, of Police Scotland, said: \"We would like to hear from anyone who was in the area of the time of the crash to contact police.\n",
      "\"We know from witnesses already spoken to that there was a white flat-bed pickup truck - the size of a transit van - on the road at the time of the crash.\n",
      "\"We are very keen to speak to the driver as he or she may have information that could prove vital to the investigation.\"\n",
      "Abstract:\n",
      "Two men have died following a road crash on the A713 in Dumfries and Galloway.\n",
      "Summary:\n",
      "\n",
      "Context Repeats Highlighted\n",
      "<pad> Two men have died in a crash on the A713 in South Ayrshire.</s>\n",
      "\n",
      "Label Repeats Highlighted\n",
      "<pad> Two men have died in a crash on the A713 in South Ayrshire.</s>\n"
     ]
    }
   ],
   "source": [
    "print_sample(prediction[0], xsum_document, repeat_type='context')\n",
    "\n",
    "print(\"Abstract:\")\n",
    "print_sample(xsum_document, xsum_summary)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print()\n",
    "print(\"Context Repeats Highlighted\")\n",
    "print_sample(xsum_document, prediction[0], repeat_type='all')\n",
    "print()\n",
    "\n",
    "print(\"Label Repeats Highlighted\")\n",
    "print_sample(xsum_document, prediction[0], repeat_type='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-Daily Mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cnn_dailymail/3.0.0 (download: 558.32 MiB, generated: 1.28 GiB, post-processed: Unknown size, total: 1.82 GiB) to /home/mila/a/arorakus/scratch/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67763589dc749768bf63ee2d8fc16f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0055e5472de8494598bf89bf465c6248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6781ff15b7430cb6b07afda354e233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/376M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58567a2aa35d474c8b776ea76f7d3406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/572k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1c8472ed8e4b0ea568991bfff5d756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/12.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de040c4776614cdda4126c9f365b33b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/661k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465a5bc17f614a0b8d8c9e8649f3d709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ebb66839004c78bd02a6f4f8baf3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433cca1a4c244f9192cf6dacc6eb3f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d43c5d29a2d452eb123d99cf65801a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cnn_dailymail downloaded and prepared to /home/mila/a/arorakus/scratch/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6bde087d3a4b1b86c24cc17c0af10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "cnn_dm_dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7776028f46c455b92f56f4cb40c35f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5c459f5314489e9259b498d4630d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5934a3f7d44392ad0c31b6ea539603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdda2d99e9f4f5480393c9ac599319f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b301fbc08c482cac7f34fa81423145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "pegasus_cnn_dailymail_tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-cnn_dailymail\")\n",
    "pegasus_cnn_dailymail_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-cnn_dailymail\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('ews')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da95f7994a94b278c1256acc4a0dec0d4d70efd24bb6c3a54d818a91a64421ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
